{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as tick\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=False)\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(output_dir,epoch,images,step,steps,loss):\n",
    "    # line smoothing for plotting loss\n",
    "    def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "        import numpy as np\n",
    "        from math import factorial\n",
    "\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "        order_range = range(order+1)\n",
    "        half_window = (window_size -1) // 2\n",
    "        b = np.mat([[k**i for i in order_range] for k\n",
    "                                        in range(-half_window, half_window+1)])\n",
    "        m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "        firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "        lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "        y = np.concatenate((firstvals, y, lastvals))\n",
    "        return np.convolve( m[::-1], y, mode='valid')\n",
    "    def k(x,pos):\n",
    "      x /= 1000.0\n",
    "      return '%.1f%s' % (x, 'K')\n",
    "\n",
    "    xs = np.linspace(0,step,len(loss[0]))\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    fig.suptitle('Epoch %d' % (epoch) , fontsize=20,x=0.55)\n",
    "\n",
    "    gs1 = gridspec.GridSpec(8,8)\n",
    "    images = images.reshape([64,28,28])\n",
    "    for i,subplot in enumerate(gs1):\n",
    "        ax = fig.add_subplot(subplot)\n",
    "        ax.imshow(images[i],cmap=plt.cm.gray)\n",
    "        ax.axis('off')\n",
    "        ax.set_axis_off()\n",
    "    gs1.tight_layout(fig, rect=[0, 0, 0.5,1])\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "\n",
    "    gs2 = gridspec.GridSpec(2,1)\n",
    "\n",
    "    c = ['#008FD5','#FF2700']\n",
    "    title = ['Generator loss','Discriminator loss']\n",
    "\n",
    "    for p in range(2):\n",
    "        ax = fig.add_subplot(gs2[p])\n",
    "        ax.plot(xs,loss[p], linewidth=1.5,alpha=0.3,c=c[p])\n",
    "        ax.plot(xs,savitzky_golay(loss[p],61,5),c=c[p])\n",
    "        ax.set_title(title[p],fontsize=12)\n",
    "        ax.set_xlabel('Step',fontsize=10)\n",
    "        ax.set_ylabel('Loss',fontsize=10)\n",
    "        ax.set_xlim([0,steps])\n",
    "        ax.xaxis.set_major_formatter(tick.FuncFormatter(k))\n",
    "\n",
    "    gs2.tight_layout(fig, rect=[0.5, 0, 1, 1])\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    file_name = output_dir + str(epoch).zfill(3)+ '.png'\n",
    "    plt.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, reuse=False, name='d'):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        h0 = tf.layers.dense(x,256,kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        h1 = tf.layers.dense(h0, 1,\n",
    "                           kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        out = tf.nn.sigmoid(h1)        \n",
    "        return out, h1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, reuse=False, name='g'):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        h0 = tf.layers.dense(z,256,\n",
    "                           kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        h0 = tf.nn.dropout(tf.nn.relu(h0), keep_prob=0.5)\n",
    "        h1 = tf.layers.dense(h0, 784,\n",
    "                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        out = tf.nn.sigmoid(h1)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define z as noise sampling and x as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "z = tf.placeholder(tf.float32, shape=[None,100])\n",
    "\n",
    "g = generator(z)\n",
    "\n",
    "d_loss_real, d_logit_real = discriminator(x)\n",
    "d_loss_fake, d_logit_fake = discriminator(g,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'g/dense/kernel:0' shape=(100, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'g/dense/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'g/dense_1/kernel:0' shape=(256, 784) dtype=float32_ref>,\n",
       " <tf.Variable 'g/dense_1/bias:0' shape=(784,) dtype=float32_ref>,\n",
       " <tf.Variable 'd/dense/kernel:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'd/dense/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'd/dense_1/kernel:0' shape=(256, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'd/dense_1/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_params = [v for v in tf.trainable_variables() if v.name.startswith('d/')]\n",
    "g_params = [v for v in tf.trainable_variables() if v.name.startswith('g/')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminannt loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=d_logit_real, labels = tf.ones_like(d_logit_real)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=d_logit_fake, labels = tf.zeros_like(d_logit_fake)))\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits = d_logit_fake, labels=tf.ones_like(d_logit_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
